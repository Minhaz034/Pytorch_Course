{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPGcH3cRPRU7"
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "X = torch.arange(0,1,0.02).unsqueeze(dim = 1)\n",
    "y = weight*X + bias"
   ],
   "metadata": {
    "id": "yMS6jF0sPXqp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X.shape, y.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20zT8DqBPbHC",
    "outputId": "3dde8cc8-d46a-495a-e869-bbb645ef54bf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_split = int(0.8* X.shape[0])\n",
    "X_train, y_train, X_test, y_test = X[:train_split], y[:train_split], X[train_split:], y[train_split:]\n",
    "train_split"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjulQ8kjPcq4",
    "outputId": "b61842ea-1d20-4ab1-82ce-7bea63423da6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pouCRbnGPfjF",
    "outputId": "0fb4aee1-c928-40cd-a6c8-b02501f99d6e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_data(train_data = X_train,\n",
    "              train_labels = y_train,\n",
    "              test_data = X_test,\n",
    "              test_labels = y_test,\n",
    "              predictions = None):\n",
    "  plt.figure(figsize = (9,4))\n",
    "  plt.scatter(train_data,train_labels, c='b',s=4,label=\"Training Data\")\n",
    "  plt.scatter(test_data,test_labels, c='g',s=4,label=\"Test Data\")\n",
    "  if predictions is not None:\n",
    "    plt.scatter(test_data,predictions, c='r',s=4,label=\"Predictions\")\n",
    "  plt.legend()\n"
   ],
   "metadata": {
    "id": "waeIp-M6PhG_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_data();"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "llNmkNe_Pi3P",
    "outputId": "50b246e4-3f57-47c6-819d-c19d8c2dec45"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch model building essentials:\n",
    "* torch.nn :Contains all the building blocks for computational graphs (a neural network can be considered a computational graph)\n",
    "* nn.Parameter: what parameters our model try and learn often pytorch layer from torch.nn will set this for us\n",
    "* torch.nn.Module - The base class for all NN modules, if you subclass it you should override forward() method\n",
    "* torch.optim - This is where the optimizers in Pytorch live, they will help with gradient descent\n",
    "* def forward() : All nn.Module subclasses must override  forward(), this method defines what happens in the forward computation"
   ],
   "metadata": {
    "id": "qfB1XNrl25RD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Building the model:\n",
    "class LinearRegressionModel(nn.Module): #nn.Module\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.weights = nn.Parameter(torch.randn(1,\n",
    "                                            requires_grad = True,\n",
    "                                            dtype = torch.float))\n",
    "    self.bias = nn.Parameter(torch.randn(1,\n",
    "                                         requires_grad = True,\n",
    "\n",
    "                                         dtype = torch.float))\n",
    "  def forward(self,X:torch.Tensor)->torch.Tensor:\n",
    "    forward_pass = self.weights * X + self.bias\n",
    "    return forward_pass\n"
   ],
   "metadata": {
    "id": "bKQ6jXt9RMj_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#create a random seed first because the model uses random values for our weights and biases.\n",
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegressionModel()\n"
   ],
   "metadata": {
    "id": "tMY118ZSTckY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(list(model_0.parameters()))\n",
    "print(model_0.state_dict())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHbgcBGLF-Pe",
    "outputId": "44abd98c-70df-48ae-ec24-30b013fbf6b9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_test,y_test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGlnSH0UHbxR",
    "outputId": "a00926e4-0d98-411a-f56c-d4b60574107a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## making predictions with torch.inference_mode()\n",
    "#we could also do it without using the inference_mode() and just running y_preds = model_0(X_test) but if we use inference_mode() it will not calculate gradients. You can also use torch.no_grad()\n",
    "with torch.inference_mode():\n",
    "  y_preds = model_0(X_test)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#   y_preds = model_0(X_test)\n",
    "\n",
    "y_test,y_preds"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IIiGXccFN63",
    "outputId": "e6d7f699-4a87-4502-9a39-89ea1ddd7ae2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# y_preds = model_0(X_test)\n",
    "# y_preds"
   ],
   "metadata": {
    "id": "yprxWPcJI-F0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_data(predictions=y_preds)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "FsxgoCCxIPs3",
    "outputId": "4aa1a0f9-4bb0-4371-87d8-57a68a01ab35"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model: The whole idea of training is the model to move from *unknown* parameters to  known representation\n",
    "# A loss function is a function to measure how wrong your predictions are from the standard values\n",
    "# what we need to train:\n",
    "#  - A loss function\n",
    "# - Optimizer : Takes into action the loss of a model and adjusts the model's parameters (weights and biases)\n",
    "# We need a training loop and a test loop\n",
    "list(model_0.parameters())\n",
    "model_0.state_dict()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "di_QzEOzv7iP",
    "outputId": "1b8e50c7-6609-422d-bb47-4393b09caef6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## setting up a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "# set up an optimizer\n",
    "optimizer = torch.optim.SGD(params= model_0.parameters(),lr=0.01)"
   ],
   "metadata": {
    "id": "ayLhysaWXbuY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#building a training loop and testing loop:\n",
    "'''\n",
    "0. Loop through the data\n",
    "1. Forward passs (this involves data moving through models forward() method) to make predictions\n",
    "2. Calculate the loss (compare forward pass predictions to groud truth labels)\n",
    "3. Optimizer zero grad\n",
    "4. Loss backward- move backwards through the network to calculate the gradients of each of the parameters with respect to the loss (backpropagation)\n",
    "5. Optimizer step: Use the optimizer to adjust our model's parameters to improve the loss (gradient descent)\n",
    "'''"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "EYXelBkZR3Dh",
    "outputId": "35c86b67-7c50-4e24-e7a4-b9b2c41b4b4a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#training\n",
    "#epoch is one loop through data\n",
    "torch.manual_seed(42)\n",
    "epochs = 150 # this is also a hyperparameter\n",
    "\n",
    "#track values\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "# 0. loop through the data\n",
    "for epoch in range(epochs):\n",
    "  model_0.train() #train mode in pytorch sets all parameters that requires gradients to requrire gradients\n",
    "  #forward pass:\n",
    "  y_pred = model_0(X_train)\n",
    "  #calculate loss:\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "  loss_values.append(loss)\n",
    "  # print(f\"Training Loss:{loss}\")\n",
    "  #.Optimizer zero grad:\n",
    "  optimizer.zero_grad()\n",
    "  # Perform backpropagation with respect to the parameters of the model\n",
    "  loss.backward()\n",
    "\n",
    "  # step the optimizer (perform gradient descent)\n",
    "  optimizer.step()\n",
    "\n",
    "  model_0.eval() #turns of diff settins not needed for evaluation or testing\n",
    "  with torch.inference_mode(): #turns off gradient tracking\n",
    "    test_pred = model_0(X_test)\n",
    "\n",
    "    #calculate the test loss:\n",
    "    test_loss = loss_fn(test_pred,y_test)\n",
    "    test_loss_values.append(test_loss)\n",
    "    # print(f\"Test loss:{test_loss}\")\n",
    "\n",
    "  epoch_count.append(epoch)\n",
    "  if epoch % 10 ==0:\n",
    "\n",
    "    print(f\"Epoch:{epoch}\\tTrain Loss:{loss}\\tTest Loss: {test_loss}\")\n",
    "    #print(model_0.state_dict())\n",
    "\n",
    "#print out model state_dict:\n",
    "# print(model_0.state_dict())\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bMcVD5JURUm",
    "outputId": "7ee1c27b-dddc-4b48-8ede-7a1f62732f74"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_0.state_dict()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iubAw40sXHLD",
    "outputId": "f119aac3-764c-405a-dac5-893ffa0d9cb3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#plot the loss curvers np.array(torch.tensor(loss_values).cpu().numpy())\n",
    "plt.plot(np.array(torch.tensor(epoch_count).cpu().numpy()), np.array(torch.tensor(loss_values).cpu().numpy()), label = \"Train Loss\")\n",
    "plt.plot(np.array(torch.tensor(epoch_count).cpu().numpy()), np.array(torch.tensor(test_loss_values).cpu().numpy()), label = \"Test Loss\")\n",
    "plt.title(\"Training and Test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "9SQI_g73mwOr",
    "outputId": "27c6b990-e6ac-4a06-f6e7-070a4fd8679f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "  y_preds_new = model_0(X_test)\n",
    "plot_data(predictions=y_preds_new)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "lPFloXbrbrWB",
    "outputId": "b6e81078-4a97-4f5b-a427-c3d0cd7d5263"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#saving our model:\n",
    "'''\n",
    "There are three main methods to saving and loading our model:\n",
    "1. torch.save() - allows you to save a Pythons pickle format\n",
    "2.torch.load() - load your saved Pytorch Object\n",
    "3. torch.nn.Module.load_state_dict() - load model's saved state dictionary\n",
    "'''"
   ],
   "metadata": {
    "id": "8vvMcU97ds09",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "outputId": "d9948e38-5e6c-479c-d22a-aea83583fcc6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for param in model_0.state_dict():\n",
    "  print(param,model_0.state_dict()[param].shape)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oPu2uuxa-0a",
    "outputId": "6618ae1d-fd3b-493e-88bc-33e8a2dc1c1f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4iWs2RCdu7p",
    "outputId": "cd5f9f60-a460-4640-e845-78b6c4b90372"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model_0.state_dict(), '/LR_model.pt')"
   ],
   "metadata": {
    "id": "TZezbAomgIYO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "SAVE_PATH = \"models/LR_model_ckpoint.pt\"\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_0.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, SAVE_PATH)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "zExxHaq9k7kh",
    "outputId": "2b5ac52b-362c-4aa7-afcd-46d71f423ef0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_model = LinearRegressionModel()\n",
    "loaded_model.load_state_dict(torch.load(\"/LR_model.pt\"))\n",
    "loaded_model.eval()"
   ],
   "metadata": {
    "id": "aqf2UHlJeLyh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(SAVE_PATH)\n",
    "print(checkpoint['loss'])\n",
    "print(checkpoint['epoch'])\n",
    "print(checkpoint['model_state_dict'])\n",
    "print(checkpoint['optimizer_state_dict'])\n"
   ],
   "metadata": {
    "id": "LpZF86YulVK2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_model.state_dict()"
   ],
   "metadata": {
    "id": "wVviAOZzhmkf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# make predictions wich loaded_model\n",
    "loaded_model.eval()\n",
    "with torch.inference_mode():\n",
    "  loaded_preds = loaded_model(X_test)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "qFtP6yPMh6b1",
    "outputId": "d6be5e15-ab24-4c18-f5c1-12e53ee83156"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_preds"
   ],
   "metadata": {
    "id": "j9z8QRVJiGL_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_preds"
   ],
   "metadata": {
    "id": "L8g8rzgurRX3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "  test_preds = model_0(X_test)\n",
    "test_preds"
   ],
   "metadata": {
    "id": "rCwPJsngrTx1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Wrapping everyting up"
   ],
   "metadata": {
    "id": "uUXyf5TwsZYn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WGls3d3Msk5k",
    "outputId": "68d91b26-7afd-4660-ec71-b8e885776754"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#write device agnostic code:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hU-TdSQTsubt",
    "outputId": "eeaec0a8-5acd-410c-f0bb-6311610261ea"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#create data\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "X = torch.arange(0,1,0.002).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "X.shape,y.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-1GJdhcs1pP",
    "outputId": "8d2a0c39-6b85-427e-c05d-0f1dcf89d667"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#spplit the data\n",
    "train_split = int(0.8*X.shape[0])\n",
    "X_train, y_train, X_test, y_test = X[:train_split], y[:train_split], X[train_split:], y[train_split:]\n",
    "X_train.shape ,y_train.shape, X_test.shape, y_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMhBPlO0t-SQ",
    "outputId": "5f75f1f4-8cb3-4350-a9b8-2fc009d389bc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_data(train_data = X_train,\n",
    "              train_labels = y_train,\n",
    "              test_data = X_test,\n",
    "              test_labels = y_test,\n",
    "              predictions = None):\n",
    "  plt.figure(figsize = (9,4))\n",
    "  plt.scatter(train_data,train_labels, c='b',s=4,label=\"Training Data\")\n",
    "  plt.scatter(test_data,test_labels, c='g',s=4,label=\"Test Data\")\n",
    "  if predictions is not None:\n",
    "    plt.scatter(test_data,predictions, c='r',s=4,label=\"Predictions\")\n",
    "  plt.legend()\n",
    "\n",
    "plot_data()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "VJG-CRVWupHh",
    "outputId": "dbd98488-1a09-481d-8e1b-3faa6ae6f995"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LRModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LRModel,self).__init__()\n",
    "    self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "  def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "    return self.linear_layer(x)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = LRModel()\n",
    "model_1, model_1.state_dict()\n",
    "model_1.to(device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KstcA0r1vS_3",
    "outputId": "8133d3db-c4a7-497a-e084-cd6b577e5736"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "next(model_1.parameters()).device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Nx4IzLm8ixe",
    "outputId": "cf0b47b4-abfe-477d-b0d4-23f0502deed0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#loss fn and optimizer\":\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params = model_1.parameters(),lr = 0.001)\n"
   ],
   "metadata": {
    "id": "i2RTomiv92s2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Training\n",
    "epoch_list = []\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_1.train()\n",
    "epochs = 800\n",
    "\n",
    "#put data on the same device:\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model_1.train()\n",
    "  epoch_list.append(epoch)\n",
    "  y_pred = model_1(X_train)\n",
    "\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "  losses.append(loss)\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    test_pred = model_1(X_test)\n",
    "    test_loss = loss_fn(test_pred, y_test)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Epoch:{epoch} | Train loss:{loss} | Test loss: {test_loss}\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYcuhFjH-0GR",
    "outputId": "d5e9fec0-18e0-41c2-b254-ff79f9bfd814"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_pred.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pBac9oUAMsz",
    "outputId": "11331d58-54c8-4697-bc5c-9d049e43b3fc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sqb2OVyBKZ8",
    "outputId": "899f6012-70a6-43e1-b3d6-0a3e735bc2f6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#plot the loss curvers np.array(torch.tensor(loss_values).cpu().numpy())\n",
    "plt.plot(np.array(torch.tensor(epoch_list).cpu().numpy()), np.array(torch.tensor(losses).cpu().numpy()), label = \"Train Loss\")\n",
    "plt.plot(np.array(torch.tensor(epoch_list).cpu().numpy()), np.array(torch.tensor(test_losses).cpu().numpy()), label = \"Test Loss\")\n",
    "plt.title(\"Training and Test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "iYo9w4pZBZiE",
    "outputId": "61ea5699-a2ec-44f2-bf38-a535bfcf201a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "  y_preds_1 = model_1(X_test)\n"
   ],
   "metadata": {
    "id": "P4bVI-IZCnxF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#checkout model preds\n",
    "plot_data(predictions=y_preds_1.cpu())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "8JOtKkUSagGW",
    "outputId": "058d1142-a5d3-47a3-bbd0-86b05665332b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents= True, exist_ok=True)\n",
    "MODEL_NAME = 'LR_model_01.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "MODEL_SAVE_PATH\n",
    "\n",
    "print(f\"Saving the model to {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj = model_1.state_dict(), f=MODEL_SAVE_PATH)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWm6nOGdalCb",
    "outputId": "3a2d4240-e9cc-4955-efd1-c2965a07656c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model:\n",
    "\n",
    "loaded_model_1 = LRModel()\n",
    "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "loaded_model_1.to(device)\n",
    "loaded_model_1.state_dict()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcO0IlNUh8ao",
    "outputId": "bdef45e0-e6f0-4ded-8946-2c8e5ee49e86"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_model_1.eval()\n",
    "with torch.inference_mode():\n",
    "  y_preds_loaded = loaded_model_1(X_test)\n",
    "y_preds_loaded == y_preds_1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuPGCRhEjDhQ",
    "outputId": "dbbe2f96-8ce3-496b-8b99-3c84c7061fa2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#exercises:"
   ],
   "metadata": {
    "id": "gPKtOIRPjYHv"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
